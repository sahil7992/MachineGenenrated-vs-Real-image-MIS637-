{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9299b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.020737,
     "end_time": "2024-03-04T16:24:56.582083",
     "exception": false,
     "start_time": "2024-03-04T16:24:56.561346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337650f",
   "metadata": {
    "papermill": {
     "duration": 27.350904,
     "end_time": "2024-03-04T16:25:23.944747",
     "exception": false,
     "start_time": "2024-03-04T16:24:56.593843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import ssl\n",
    "import torcheval\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31659d",
   "metadata": {
    "papermill": {
     "duration": 0.108314,
     "end_time": "2024-03-04T16:25:37.026977",
     "exception": false,
     "start_time": "2024-03-04T16:25:36.918663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c529882",
   "metadata": {
    "papermill": {
     "duration": 0.021642,
     "end_time": "2024-03-04T16:25:37.061803",
     "exception": false,
     "start_time": "2024-03-04T16:25:37.040161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"archive\")\n",
    "ai_dir = data_path / \"AiArtData\" / \"AiArtData\"\n",
    "real_dir = data_path / \"RealArt\" / \"RealArt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0dd64",
   "metadata": {
    "papermill": {
     "duration": 1.005244,
     "end_time": "2024-03-04T16:25:38.080144",
     "exception": false,
     "start_time": "2024-03-04T16:25:37.074900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai_image_path_list = list(Path(ai_dir).glob(\"*.jpg\"))\n",
    "random_ai_image = random.sample(ai_image_path_list, k=3)\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "i = 1\n",
    "for image_path in random_ai_image:\n",
    "    plt.subplot(1, 3, i)\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4518b2",
   "metadata": {
    "papermill": {
     "duration": 2.056662,
     "end_time": "2024-03-04T16:25:40.150527",
     "exception": false,
     "start_time": "2024-03-04T16:25:38.093865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_image_path_list = list(Path(real_dir).glob(\"*.jpg\"))\n",
    "random_real_image = random.sample(real_image_path_list, k=3)\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "i = 1\n",
    "for image_path in random_real_image:\n",
    "    plt.subplot(1, 3, i)\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440aa77",
   "metadata": {
    "papermill": {
     "duration": 0.125109,
     "end_time": "2024-03-04T16:25:40.348079",
     "exception": false,
     "start_time": "2024-03-04T16:25:40.222970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data_path = Path(\"kaggle/working/data\")\n",
    "new_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_path = new_data_path / \"train\"\n",
    "test_path = new_data_path / \"test\"\n",
    "\n",
    "os.mkdir(train_path)\n",
    "os.mkdir(test_path)\n",
    "\n",
    "train_ai_split = int(len(ai_image_path_list) * 0.8)\n",
    "train_real_split = int(len(real_image_path_list) * 0.8)\n",
    "\n",
    "train_ai_img = random.sample(ai_image_path_list, k=train_ai_split)\n",
    "train_real_img = random.sample(real_image_path_list, k=train_real_split)\n",
    "\n",
    "test_ai_img = []\n",
    "test_real_img = []\n",
    "\n",
    "for ai_img in ai_image_path_list:\n",
    "    if ai_img not in train_ai_img:\n",
    "        test_ai_img.append(ai_img)\n",
    "    \n",
    "for real_img in real_image_path_list:\n",
    "    if real_img not in train_real_img:\n",
    "        test_real_img.append(real_img)\n",
    "print(f\"ai_image_path_list: {len(ai_image_path_list)}\")\n",
    "print(f\"real_image_path_list: {len(real_image_path_list)}\")\n",
    "print(f\"train_ai_img: {len(train_ai_img)}\")\n",
    "print(f\"train_real_img: {len(train_real_img)}\")\n",
    "print(f\"test_ai_img: {len(test_ai_img)}\")\n",
    "print(f\"test_real_img: {len(test_real_img)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedaeac",
   "metadata": {
    "papermill": {
     "duration": 0.0272,
     "end_time": "2024-03-04T16:25:40.392251",
     "exception": false,
     "start_time": "2024-03-04T16:25:40.365051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ai_path = train_path / \"AiArt\"\n",
    "train_real_path = train_path / \"RealArt\"\n",
    "test_ai_path = test_path / \"AiArt\"\n",
    "test_real_path = test_path / \"RealArt\"\n",
    "\n",
    "os.mkdir(train_ai_path)\n",
    "os.mkdir(train_real_path)\n",
    "os.mkdir(test_ai_path)\n",
    "os.mkdir(test_real_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058f588",
   "metadata": {
    "papermill": {
     "duration": 9.563698,
     "end_time": "2024-03-04T16:25:49.972678",
     "exception": false,
     "start_time": "2024-03-04T16:25:40.408980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img in train_ai_img:\n",
    "    shutil.copy(img, train_ai_path)\n",
    "for img in train_real_img:\n",
    "    shutil.copy(img, train_real_path)\n",
    "for img in test_ai_img:\n",
    "    shutil.copy(img, test_ai_path)\n",
    "for img in test_real_img:\n",
    "    shutil.copy(img, test_real_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f75ab6",
   "metadata": {
    "papermill": {
     "duration": 0.025176,
     "end_time": "2024-03-04T16:25:50.054201",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.029025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = torchvision.models.ResNet152_Weights.DEFAULT\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a62b27",
   "metadata": {
    "papermill": {
     "duration": 0.025538,
     "end_time": "2024-03-04T16:25:50.094792",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.069254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780d147",
   "metadata": {
    "papermill": {
     "duration": 0.03059,
     "end_time": "2024-03-04T16:25:50.141828",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.111238",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_path,\n",
    "                                 transform=auto_transforms)\n",
    "test_data = datasets.ImageFolder(root=test_path,\n",
    "                                transform=auto_transforms)\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdc75f",
   "metadata": {
    "papermill": {
     "duration": 0.024996,
     "end_time": "2024-03-04T16:25:50.182860",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.157864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fc3fe",
   "metadata": {
    "papermill": {
     "duration": 0.269461,
     "end_time": "2024-03-04T16:25:50.468142",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.198681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df1bda",
   "metadata": {
    "papermill": {
     "duration": 0.027326,
     "end_time": "2024-03-04T16:25:50.511179",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.483853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "num_workers = os.cpu_count()\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                             batch_size=32,\n",
    "                             num_workers=num_workers,\n",
    "                             shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                            batch_size=32,\n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False)\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\"mps\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc3ac6",
   "metadata": {
    "papermill": {
     "duration": 3.255801,
     "end_time": "2024-03-04T16:25:53.782366",
     "exception": false,
     "start_time": "2024-03-04T16:25:50.526565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet152(weights=\"IMAGENET1K_V2\").to(device)\n",
    "model = torchvision.models.resnet152(weights=\"IMAGENET1K_V2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ccbca9",
   "metadata": {
    "papermill": {
     "duration": 1.54089,
     "end_time": "2024-03-04T16:25:55.341306",
     "exception": false,
     "start_time": "2024-03-04T16:25:53.800416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a83ce",
   "metadata": {
    "papermill": {
     "duration": 0.046748,
     "end_time": "2024-03-04T16:25:55.417449",
     "exception": false,
     "start_time": "2024-03-04T16:25:55.370701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.bn1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f2ad9",
   "metadata": {
    "papermill": {
     "duration": 0.388464,
     "end_time": "2024-03-04T16:25:55.826048",
     "exception": false,
     "start_time": "2024-03-04T16:25:55.437584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b473c1",
   "metadata": {
    "papermill": {
     "duration": 0.02972,
     "end_time": "2024-03-04T16:25:55.876316",
     "exception": false,
     "start_time": "2024-03-04T16:25:55.846596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35e809",
   "metadata": {
    "papermill": {
     "duration": 0.048224,
     "end_time": "2024-03-04T16:25:55.945200",
     "exception": false,
     "start_time": "2024-03-04T16:25:55.896976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "nn.Dropout(p=0.5),   \n",
    "nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
    "nn.Dropout(p=0.5),\n",
    "nn.Linear(in_features=1024, out_features=1, bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f41b3d",
   "metadata": {
    "papermill": {
     "duration": 0.029777,
     "end_time": "2024-03-04T16:25:55.995369",
     "exception": false,
     "start_time": "2024-03-04T16:25:55.965592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a0064",
   "metadata": {
    "papermill": {
     "duration": 0.3386,
     "end_time": "2024-03-04T16:25:56.354862",
     "exception": false,
     "start_time": "2024-03-04T16:25:56.016262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model=model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ebba5",
   "metadata": {
    "papermill": {
     "duration": 0.033294,
     "end_time": "2024-03-04T16:25:56.459208",
     "exception": false,
     "start_time": "2024-03-04T16:25:56.425914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78902874",
   "metadata": {
    "papermill": {
     "duration": 14.887263,
     "end_time": "2024-03-04T16:26:11.369476",
     "exception": false,
     "start_time": "2024-03-04T16:25:56.482213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    metric = BinaryAccuracy(threshold=0.5)\n",
    "    metric.update(y_pred, y_true)\n",
    "    return metric.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6f978",
   "metadata": {
    "papermill": {
     "duration": 0.097132,
     "end_time": "2024-03-04T16:26:11.489355",
     "exception": false,
     "start_time": "2024-03-04T16:26:11.392223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_fn(torch.tensor([0, 0, 0, 1]), torch.Tensor([0.2, 0.9, 0.9, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor device:\", img.device)  # Check device\n",
    "print(\"Model device:\", next(model.parameters()).device)  # Ensure model is on MPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img.to(device)\n",
    "# label = label.to(device)  \n",
    "# print(\"Moved image dtype and device:\", img.dtype, img.device) \n",
    "# model.to(device)\n",
    "# print(\"Model parameters dtype and device:\", next(model.parameters()).dtype, next(model.parameters()).device)  # Check\n",
    "# img, label = next(iter(train_dataloader))\n",
    "# print(\"Original image dtype and device:\", img.dtype, img.device)\n",
    "\n",
    "# pred = model(img)\n",
    "# print(\"Prediction results:\", pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de0beb",
   "metadata": {
    "papermill": {
     "duration": 3.94104,
     "end_time": "2024-03-04T16:26:15.455694",
     "exception": false,
     "start_time": "2024-03-04T16:26:11.514654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "img, label = next(iter(train_dataloader))\n",
    "# print(img,label)\n",
    "print(len(img))\n",
    "# i=img\n",
    "pred = model(img)\n",
    "\n",
    "print(pred.squeeze())\n",
    "print(torch.sigmoid(pred.squeeze()))\n",
    "pred.squeeze().shape, label.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b826a5",
   "metadata": {
    "papermill": {
     "duration": 0.040547,
     "end_time": "2024-03-04T16:26:15.519189",
     "exception": false,
     "start_time": "2024-03-04T16:26:15.478642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              optimizer: torch.optim.Optimizer,\n",
    "              accuracy_fn):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(X).squeeze()\n",
    "        \n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=torch.sigmoid(y_pred))\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            test_pred_logits = model(X).squeeze()\n",
    "            \n",
    "            loss = loss_fn(test_pred_logits, y.float())\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=torch.sigmoid(test_pred_logits))\n",
    "            \n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586c2e1",
   "metadata": {
    "papermill": {
     "duration": 0.0361,
     "end_time": "2024-03-04T16:26:15.579143",
     "exception": false,
     "start_time": "2024-03-04T16:26:15.543043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "         loss_fn: torch.nn.Module,\n",
    "         optimizer: torch.optim.Optimizer,\n",
    "         train_dataloader: torch.utils.data.DataLoader,\n",
    "         test_dataloader: torch.utils.data.DataLoader,\n",
    "         accuracy_fn,\n",
    "         epochs: int = 5):\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          accuracy_fn=accuracy_fn)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        accuracy_fn=accuracy_fn)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "597078bc",
   "metadata": {
    "papermill": {
     "duration": 126.678,
     "end_time": "2024-03-04T16:28:22.279716",
     "exception": false,
     "start_time": "2024-03-04T16:26:15.601716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.mps.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "results = train(model=model,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               train_dataloader=train_dataloader,\n",
    "               test_dataloader=test_dataloader,\n",
    "               epochs=10)\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c2fd4",
   "metadata": {
    "papermill": {
     "duration": 0.039597,
     "end_time": "2024-03-04T16:28:22.343380",
     "exception": false,
     "start_time": "2024-03-04T16:28:22.303783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92215dca",
   "metadata": {
    "papermill": {
     "duration": 0.65756,
     "end_time": "2024-03-04T16:28:23.025208",
     "exception": false,
     "start_time": "2024-03-04T16:28:22.367648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2eb8b",
   "metadata": {
    "papermill": {
     "duration": 0.032199,
     "end_time": "2024-03-04T16:28:23.083786",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.051587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# torch.cuda.manual_seed(42)\n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "\n",
    "# start_time = timer()\n",
    "\n",
    "# results_20_epochs = train(model=model,\n",
    "#                loss_fn=loss_fn,\n",
    "#                optimizer=optimizer,\n",
    "#                accuracy_fn=accuracy_fn,\n",
    "#                train_dataloader=train_dataloader,\n",
    "#                test_dataloader=test_dataloader,\n",
    "#                epochs=20)\n",
    "\n",
    "# end_time = timer()\n",
    "\n",
    "# print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5814f",
   "metadata": {
    "papermill": {
     "duration": 0.031445,
     "end_time": "2024-03-04T16:28:23.139745",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.108300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_loss_curves(results_20_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc2c59",
   "metadata": {
    "papermill": {
     "duration": 0.429102,
     "end_time": "2024-03-04T16:28:23.592890",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.163788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"kaggle/working/model\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"resnet152_ai_vs_real_img_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "torch.save(obj=model.state_dict(),\n",
    "          f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad171d",
   "metadata": {
    "papermill": {
     "duration": 0.032832,
     "end_time": "2024-03-04T16:28:23.650587",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.617755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# import torch\n",
    "# from pathlib import Path\n",
    "# import matplotlib as plt\n",
    "# model = torchvision.models.resnet152(weights=\"IMAGENET1K_V2\")\n",
    "# model.fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "# model.load_state_dict(torch.load(f=\"/kaggle/input/resnet152_ai_vs_real_img_model/pytorch/model/1/resnet152_ai_vs_real_img_model.pth\", map_location=torch.device(\"cpu\")))\n",
    "# device = \"cpu\"\n",
    "# model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dca1b1",
   "metadata": {
    "papermill": {
     "duration": 0.039818,
     "end_time": "2024-03-04T16:28:23.714620",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.674802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str, \n",
    "                        class_names: List[str],\n",
    "                        label,\n",
    "                        image_size: Tuple[int, int] = (224, 224),\n",
    "                        transform: torchvision.transforms = None,\n",
    "                        device: torch.device=device,\n",
    "                       ):\n",
    "    \n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      \n",
    "      transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "\n",
    "      target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    target_image_pred_probs = torch.sigmoid(target_image_pred).squeeze()\n",
    "    target_image_pred_label = torch.round(target_image_pred_probs).int()\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    if class_names[target_image_pred_label] == label:\n",
    "        plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs:.3f} | Label: {label}\", c=\"g\")\n",
    "    else:\n",
    "        plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs:.3f} | Label: {label}\", c=\"r\")\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74171762",
   "metadata": {
    "papermill": {
     "duration": 4.075804,
     "end_time": "2024-03-04T16:28:27.814738",
     "exception": false,
     "start_time": "2024-03-04T16:28:23.738934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "num_images_to_plot = 5\n",
    "test_real_list = list(Path(test_path).glob(\"RealArt/*.jpg\")) \n",
    "test_real_sample = random.sample(population=test_real_list, \n",
    "                                       k=num_images_to_plot) \n",
    "test_ai_list = list(Path(test_path).glob(\"AiArt/*.jpg\")) \n",
    "test_ai_sample = random.sample(population=test_ai_list, \n",
    "                                       k=num_images_to_plot) \n",
    "\n",
    "\n",
    "for image_path in test_real_sample:\n",
    "    pred_and_plot_image(model=model, \n",
    "                        image_path=image_path,\n",
    "                        class_names=class_names,\n",
    "                        transform=weights.transforms(),\n",
    "                        image_size=(224, 224),\n",
    "                       label=\"RealArt\")\n",
    "for image_path in test_ai_sample:\n",
    "    pred_and_plot_image(model=model, \n",
    "                        image_path=image_path,\n",
    "                        class_names=class_names,\n",
    "                        transform=weights.transforms(),\n",
    "                        image_size=(224, 224),\n",
    "                       label=\"AiArt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5295e35",
   "metadata": {
    "papermill": {
     "duration": 2.959326,
     "end_time": "2024-03-04T16:28:30.845785",
     "exception": false,
     "start_time": "2024-03-04T16:28:27.886459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = test_step(model, test_dataloader, loss_fn, accuracy_fn)\n",
    "print(f\"Accuracy of model on test data: {test_acc * 100 :.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c59acf",
   "metadata": {
    "papermill": {
     "duration": 0.062979,
     "end_time": "2024-03-04T16:28:30.969787",
     "exception": false,
     "start_time": "2024-03-04T16:28:30.906808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4423404,
     "sourceId": 7598969,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 221.140765,
   "end_time": "2024-03-04T16:28:33.563415",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-04T16:24:52.422650",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0edfdf4ec52b43669a37a1559d8352ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24cfc08e3c054a5ab6e8595668d694a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4256447e8a7940b78d684c57515bc35f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0edfdf4ec52b43669a37a1559d8352ea",
       "placeholder": "​",
       "style": "IPY_MODEL_ee38e6f936184d92ae3c96477d1b67cb",
       "value": "100%"
      }
     },
     "468a38cd8e8a44499628c5af467dcd0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4256447e8a7940b78d684c57515bc35f",
        "IPY_MODEL_cf614c5a7ac04f96ba2eebf0c41898cf",
        "IPY_MODEL_d50e77ebdbd04ef2a8b387f653d587ea"
       ],
       "layout": "IPY_MODEL_e2776cc4a9de4f07b5b520059f4fb869"
      }
     },
     "8ea968416719421fb515f6ef2a30676e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cf614c5a7ac04f96ba2eebf0c41898cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_24cfc08e3c054a5ab6e8595668d694a1",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8ea968416719421fb515f6ef2a30676e",
       "value": 10
      }
     },
     "d50e77ebdbd04ef2a8b387f653d587ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6a9c508538b4621a0fa1112eda931d6",
       "placeholder": "​",
       "style": "IPY_MODEL_d9f4012a8b4d471d884b39ec8453dde2",
       "value": " 10/10 [02:06&lt;00:00, 12.63s/it]"
      }
     },
     "d6a9c508538b4621a0fa1112eda931d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f4012a8b4d471d884b39ec8453dde2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e2776cc4a9de4f07b5b520059f4fb869": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee38e6f936184d92ae3c96477d1b67cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
